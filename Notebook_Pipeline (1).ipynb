{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###` Ce document Google collab a pour but de présenter le pipeline utilisé lors du projet BILL ainsi que les différentes commandes des différents outils qui le constituent `###\n",
        "\n",
        "Document réalisé par :  \n",
        "MECHKOURI Nazim : sabri-nazim.mechkouri@etu.umontpellier.fr\n",
        "& OLLAGNIER Mathilde : mathilde.ollagnier@etu.umontpellier.fr"
      ],
      "metadata": {
        "id": "2xnYwkI-ulKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1kPSDZ4a1e-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie script personnalisé : VCFReader #\n",
        "\n",
        "####pour toute information concernant le fonctionnement du script, son usage ou le code, veuillez vous dirigez vers le lien GitHub suivant : https://github.com/Senwei1/BILL####\n",
        "\n",
        "# Informations supplémentaires #\n",
        "__authors__ = (\"Nazim MECHKOURI\")\n",
        "\n",
        "__contact__ = (\"sabri-nazim.mechkouri@etu.umontpellier.fr\")\n",
        "\n",
        "__version__ = \"1.0.2\"\n",
        "\n",
        "__date__ = \"17/02/2023\"\n",
        "\n",
        "__licence__ =  \n",
        "\n",
        "        \"This program is free software: you can redistribute it and/or modify\n",
        "        it under the terms of the GNU General Public License as published by\n",
        "        the Free Software Foundation, either version 3 of the License, or\n",
        "        (at your option) any later version.\n",
        "\n",
        "        This program is distributed in the hope that it will be useful,\n",
        "        but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "        MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
        "        GNU General Public License for more details.\n",
        "        \n",
        "        You should have received a copy of the GNU General Public License\n",
        "        along with this program. If not, see <https://www.gnu.org/licenses/>.\"\n"
      ],
      "metadata": {
        "id": "T4Ae83JdoMV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###      Configuration de l'environnement pour snakemake :      ####\n",
        "\n",
        "#Tout d'abord, l'arborescence du repertoire doit ressembler à cette configuration : #\n",
        "\n",
        " Arborescence à respecter : \n",
        " Analyse\n",
        " |____P30\n",
        " | |__P30.C6\n",
        " |     |__P30.C6_all.fastq.gz\n",
        " | |____P20\n",
        " | |__P20\n",
        " |     |__P20.C1_all.fastq.gz\n",
        " |____BILL\n",
        " | |___sequence.fasta\n",
        " | |___ Script\n",
        " |       |__cluster_config.yaml\n",
        " |       |__config.yaml\n",
        " |       |__extract_sv.py\n",
        " |       |__Snakefile\n",
        " |       |__snakemake.sh\n",
        " | \n",
        " |________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "#ensuite, la configuration du snakemake pour lui accorder le chemin des fichiers d'entrée et de sortie : #\n",
        "raw_dir: \"analyse/\"\n",
        "ref_dir: \"data_copie/\"\n",
        "res_dir: \"analyse/\"\n",
        "log_dir: \"LOGS/Ref\"\n",
        "ben_dir: \"BENCHMARKS/Ref/\"\n",
        "\n",
        "ref_file: \"reference.fasta\"\n",
        "trim: 1000\n",
        "genome_size: 295052\n",
        "#genome_size: 295179\n",
        "\n",
        "\n",
        "############ FUSION DES FICHIERS AVANT ENTREE DANS LE PIPELINE #############\n",
        "\n",
        "\n",
        "### dans le répértoire où se situe l'ensemble des fastq barcodés sorties du séquenceur ###\n",
        "\n",
        "cat *.fastq > \"$i\".fastq\n"
      ],
      "metadata": {
        "id": "gBZ9AH7p9AjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***` Ce Document a pour but d'expliquer le pipeline d'analyse bioinformatique, ainsi que le fonctionnement du SnakeMake utilisé lors de ce projet `***##\n",
        "\n",
        "\n",
        "# PARTIE CONTROLE DE LA QUALITE #\n",
        "\n",
        "##`PYCOQC `##\n",
        "\n",
        "PycoQC : Outil de contrôle qualité, permet de donner une vue d'ensemble de la qualité des bases après le BaseCalling\n",
        "\n",
        "-Entrée : fichiers summary_sequence.txt produits par le sequenceur (BaseCaller : Guppy)\n",
        "\n",
        "-Utilité : produit un ensemble de graphiques a partir des fichiers en sortie du basecalling. fournit un ensemble structuré d'analyses des données en entrée a\n",
        "n de percevoir les éventuels problèmes\n",
        "de qualité de nos séquences avant la suite des analyses. Parmi les critères de contrôle qualité des données, on peut citer :\n",
        "    - Basecalled reads length : informations sur la taille des reads totaux.\n",
        "    -  PHRED score : score de qualité donnant une idée sur le taux d'erreur du BaseCalling, un score de 10 représente 10% de taux d'erreur. \n",
        "    - Read quality over experiment time : le score des bases séquencés en fonction de la durée du séquençage\n",
        "    - Number of reads per barcode : répartition des échantillons du même pool, afin de percevoir d'eventuels problèmes lors de la fabrication des librairies. \n",
        "\n",
        "\n",
        "-Sortie : lien HTML vers une visualisation globale de la qualité des données\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PIvyia1yPDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Commande pour executer PycoQC sur nos fichiers ###\n",
        "\n",
        "/students/BILL/Groupe06/data/F2_salle1/sequencing_summary_FAU70539_204952ac.txt -o pycoQC_output_F2Salle1.html"
      ],
      "metadata": {
        "id": "CSObCU8bCjWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##` SeqKit  `##\n",
        "\n",
        "Seqkit Seq : Cette commande permet d’exécuter en partie SeqKit stats produisant des statistiques de base (comme PycoQC)\n",
        "sur nos bases avec un filtre prenant en compte que les reads au dessus de 500pb.\n",
        "\n",
        "Seqkit Seq permet également d'executer l'option seqkit Trimm, qui permet d'enlever les séquenceurs adaptatrices utilisées pour le séquençage. Cette étape est nécéssaire pour avoir un bon alignement pour l'étape qui va suivre.\n",
        "\n",
        "entrée : fichiers Fastq\n",
        "\n",
        "sortie : fichiers Fastq trimmé (.trimmed)"
      ],
      "metadata": {
        "id": "qm-u998MCXsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ### Commande pour executer PycoQC sur nos fichiers ###\n",
        " \n",
        " seqkit stats \"$file\" >> /students/BILL/Groupe06/sekit/sekit_F2S1 "
      ],
      "metadata": {
        "id": "FbjfpISlC4wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Alignement  #\n",
        "\n",
        "##`  Minimap2  `##\n",
        " \n",
        "L'outil Minimap2 est un logiciel d'alignement de séquences d'ADN ou d'ARN à haute performance. Il est utilisé pour trouver des régions similaires entre deux séquences. \n",
        "L'alignement de ces séquences sur une référence génomique permet de corriger les erreurs d'assemblage et d'améliorer la qualité du génome assemblé.\n",
        "\n",
        "-Entrée : Un fichier fastq.trimmed  + Un fichier Fasta contenant le génome de référence\n",
        "\n",
        "-Sortie : des fichiers SAM (Sequence Alignement Mapping) des reads après alignement."
      ],
      "metadata": {
        "id": "dq16kb0uPX2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Commandes snakeMake pour executer le pipeline ###\n",
        "## Les lignes de commandes sont celles executées par notre groupe (groupe6) concernant l'échantillon P30.C6 ##\n",
        "\n",
        "## Première commande sert à donner le chemin du fichier config.yaml necessaire pour obtenir les répértoires d'entrée et de sortie du snakemake, ainsi que le fichier de sortie flagstat pour les statistiques avant alignement ! #\n",
        "snakemake -s SCRIPTS/Snakefile --cores 1 --keep-going --cluster-config SCRIPTS/config.yaml Analyse/P30/P30C6_all/P30C6_all.trimed1000.flagstat\n",
        "\n",
        "\n",
        "## Seconde commande Bash permet d'executer la ligne de commande produisant des VCF a partir des  fichiers BAM.mapped.sorted.vcf : donc les fichiers obtenus après execution de minimap2, suivi de SAMTools view (production BAM à partir des SAM), et SAMTools Sort (filtrer les reads mal alignés).\n",
        "\n",
        "snakemake -s SCRIPTS/Snakefile --cores 1 --keep-going --cluster-config SCRIPTS/config.yaml Analyse/P30/P30C6_all/P30C6_all.trimed1000.mapped.sorted.vcf"
      ],
      "metadata": {
        "id": "6e8mPKgBC5WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tri et filtrage des données #\n",
        "\n",
        "##` SAMTools `##\n",
        "\n",
        "L'outil SAMtools est un logiciel d'analyse de fichiers de séquençage d'ADN ou d'ARN au format SAM (Sequence Alignment/Map) ou BAM (Binary Alignment/Map). \n",
        "Il permet également de lire, écrire, éditer, indexer et visualiser les fichiers de format SAM/BAM/CRAM.\n",
        "Ce dernier est composé d'un ensemble d'outils permettant le traitement et l'alignement des reads, y compris l'indexation, mais également l'appel de variants (avec l'aide de la suite BCFtools), et une visualisation des alignements.\n",
        "\n",
        "Entrée  : fichier SAM produit par l'alignement par Minimap2\n",
        "\n",
        "Sortie : des fichiers BAM (option SAMTools view) depuis les fichiers SAM. Ces derniers vont permettre de produire : des BAM.indexed (SAMTools index), BAM.sorted (SAMTools sort). \n",
        "\n",
        "NB : il existe également l'option SAMTools flagstat prend en entrée des fichiers SAM non trié encore, et produit une sortie txt sur le ratio de reads mappés/non_mappés.\n"
      ],
      "metadata": {
        "id": "2E7ENiVIPcSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Variant Calling  #\n",
        "\n",
        "##`  Sniffles  `##\n",
        "\n",
        "Sniffles est un logiciel de détection de variants génétiques à partir de données de séquençage de génomes. \n",
        "Plus précisément, Sniffles est un outil de variant calling pour la détection des insertions et des délétions de séquences d'ADN à partir de fichiers BAM ou CRAM alignés sur une référence génomique.\n",
        "\n",
        "Entrée : fichiers BAM triés\\filtrés ainsi que les BAM indexés\n",
        "\n",
        "Sortie : Fichiers VCF (Variant Calling Files)"
      ],
      "metadata": {
        "id": "28Hfwu3KPfVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Nous nous pouvions pas avoir accès a la ligne de commande pour  Sniffle executée par snakemake. Cependant dans le gitHub de l'outil en question on peut trouver  la commande suivant pour produire des VCF : ###\n",
        "\n",
        "sniffles -i mapped_input.bam -v output.vcf\n",
        "\n",
        "\n",
        "### Ce dernier prend en entrée 1 fichier BAM.mapped.sorted et 1 fichiers BAM.indexed en input, afin de produire un ficheir VCF en output. ###"
      ],
      "metadata": {
        "id": "choT5zvKC6Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " #   Visualisation des données #\n",
        "\n",
        "##`  DeepTools  `##\n",
        "\n",
        " DeepTools qui est  est une suite d'outils python  développés pour l'analyse efficace des données de séquençage à haut débit. \n",
        " DeepTools est un ensemble d'outils permettant de modifier des fichiers BAM par exemple avec BAMCoverage comme nous l'avons vu précédemment afin de transformer nos fichiers BAM en BigWig. \n",
        " Avec plotProfile DeepTools permet également de produire des Plots en se basant sur nos données séquencées  pour une meilleure visualisation. \n",
        " DeepTools  réalise également une normalisation des données qui permet la comparaison visuelle de nos séquences avec le génome de référence\n",
        "\n",
        " Entrée : fichiers BAM trimmed.mapped.sorted et des fichiers BAM.indexed\n",
        "\n",
        " Sortie : fichiers Bedgraph\\BigWig (`Option BamCoverage`) ainsi que des fichiers pdf pour la visualisation de la profondeur en mutant (`Option PlotCoverage`)"
      ],
      "metadata": {
        "id": "x4iROFBSPiIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvYp6jC64vs6"
      },
      "outputs": [],
      "source": [
        "### ligne de commande pour executer l'option BamCoverage de DeepTools afin de produire des Bedgraph en output ###\n",
        "\n",
        "bamCoverage -b P30C6_all.trimed1000.mapped.sorted.bam -o P30C6_all.trimed1000.mapped.sorted.bedgraph --outFileFormat bedgraph --effectiveGenomeSize 295052 --normalizeUsing RPGC\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Ligne de commande Plot coverage prenant en input les fichiers BAM afin de produire en output un fichier PDF avec des graphiques de la profondeur des reads ###\n",
        "\n",
        "plotCoverage -b Analyse/P30/P30C6_all/P30C6_all.trimed1000.mapped.sorted.bam -o Analyse/P30/P30C6_all/P30C6_all.trimed1000.mapped.sorted/plotCoverage.pdf --smartlabels --plotFileFormat pdf"
      ],
      "metadata": {
        "id": "qznOWdll8D3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}